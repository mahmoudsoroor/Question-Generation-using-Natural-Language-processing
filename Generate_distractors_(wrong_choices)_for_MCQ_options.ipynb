{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "U9wmEDvr7sFB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIkuRwdJ4aTg"
      },
      "source": [
        "## Sample Text : The Nile River\n",
        "\n",
        "The Greek historian knew what he was talking about. The Nile River fed Egyptian civilization for hundreds of years.\n",
        "\n",
        "The Longest River, The Nile is 4,160 miles long - the world’s longest river. It begins near the equator in Africa and flows north to the Mediterranean Sea.\n",
        "\n",
        "In the south it churns with cataracts. A cataract is a waterfall. Near the sea the Nile branches into a delta. A delta is an area near a river’s mouth where the water deposits fine soil called silt. In the delta, the Nile divides into many streams.\n",
        "\n",
        "The river is called the upper Nile in the south and the lower Nile in the north. For centuries, heavy rains in Ethiopia caused the Nile to flood every summer. The floods deposited rich soil along the Nile’s shores. This soil was fertile, which means it was good for growing crops. Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IADmXId46hg"
      },
      "source": [
        "## Question : Which is the world's longest river ?\n",
        "a) ____________________________________\n",
        "\n",
        "b) Nile\n",
        "\n",
        "c) ____________________________________\n",
        "\n",
        "d) ____________________________________\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Nile -------------------->  Distractor generation algorithms ------> Missisipi, Amazon , Yangtze\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IMp4TmB6hFJ"
      },
      "source": [
        "## 1. Using Wordnet to generate distractors (Wrong Choices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9mzE1FI3xiV"
      },
      "source": [
        "https://wordnet.princeton.edu/citing-wordnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkTS7Z7M6vjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0790f8a8-b5b6-47da-a17e-f95f6d0957c2"
      },
      "source": [
        "!pip install nltk==3.5.0\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nltk==3.5.0\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.5.0) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.5.0) (1.4.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from nltk==3.5.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk==3.5.0) (4.67.1)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434675 sha256=8ad70b8e1a75b309ab588dd6c7245a54b6f67f1fc0e24c8b8f68cada35ac718a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/15/d3/9d3c11455a8402f6764680d7a19167d667203522cbc07262e8\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nltk-3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z13MspCd78rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1489b28-00a5-496e-e996-90b92385343b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmiQSn978uNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a714991e-7e2c-4846-a86c-521ee6be785e"
      },
      "source": [
        "# synset single\n",
        "\n",
        "word = \"nile\"\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word)\n",
        "\n",
        "for syn in syns:\n",
        "  print (syn, \": \",syn.definition(),\"\\n\" )\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('nile.n.01') :  the world's longest river (4150 miles); flows northward through eastern Africa into the Mediterranean; the Nile River valley in Egypt was the site of the world's first great civilization \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCr8ja0h-z2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6f0b92-20d1-4207-8db1-8f25dd0e8f67"
      },
      "source": [
        "# synset multiple\n",
        "\n",
        "word = \"bat\"\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word)\n",
        "\n",
        "for syn in syns:\n",
        "  print (syn, \": \",syn.definition(),\"\\n\" )\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('bat.n.01') :  nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate \n",
            "\n",
            "Synset('bat.n.02') :  (baseball) a turn trying to get a hit \n",
            "\n",
            "Synset('squash_racket.n.01') :  a small racket with a long handle used for playing squash \n",
            "\n",
            "Synset('cricket_bat.n.01') :  the club used in playing cricket \n",
            "\n",
            "Synset('bat.n.05') :  a club used for hitting a ball in various games \n",
            "\n",
            "Synset('bat.v.01') :  strike with, or as if with a baseball bat \n",
            "\n",
            "Synset('bat.v.02') :  wink briefly \n",
            "\n",
            "Synset('bat.v.03') :  have a turn at bat \n",
            "\n",
            "Synset('bat.v.04') :  use a bat \n",
            "\n",
            "Synset('cream.v.02') :  beat thoroughly and conclusively in a competition or fight \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq2MNTknNz-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868746f1-af06-42d7-ecc8-f1adfd68b340"
      },
      "source": [
        "# get only noun synsets\n",
        "\n",
        "\n",
        "# Question : Which of these is a nocturnal animal that flies?\n",
        "# a) _________\n",
        "# b) _________\n",
        "# c) bat\n",
        "# d) _________\n",
        "\n",
        "\n",
        "word = \"bat\"\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word,'n')\n",
        "\n",
        "for syn in syns:\n",
        "  print (syn, \": \",syn.definition(),\"\\n\" )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('bat.n.01') :  nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate \n",
            "\n",
            "Synset('bat.n.02') :  (baseball) a turn trying to get a hit \n",
            "\n",
            "Synset('squash_racket.n.01') :  a small racket with a long handle used for playing squash \n",
            "\n",
            "Synset('cricket_bat.n.01') :  the club used in playing cricket \n",
            "\n",
            "Synset('bat.n.05') :  a club used for hitting a ball in various games \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GylLV4rp_L5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c142bb65-57be-45fc-88db-599b2dbe148d"
      },
      "source": [
        "# Get hypernyms for a synset\n",
        "\n",
        "word = \"lion\"\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word,'n')\n",
        "\n",
        "\n",
        "hypernym = syns[0].hypernyms()\n",
        "print (hypernym)\n",
        "print (hypernym[0].hyponyms())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('big_cat.n.01')]\n",
            "[Synset('cheetah.n.01'), Synset('jaguar.n.01'), Synset('leopard.n.02'), Synset('liger.n.01'), Synset('lion.n.01'), Synset('saber-toothed_tiger.n.01'), Synset('snow_leopard.n.01'), Synset('tiger.n.02'), Synset('tiglon.n.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTu7WgJF8pBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97d57fc-9338-4e90-fc46-93b858f78d9d"
      },
      "source": [
        "# Distractors from Wordnet\n",
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0:\n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "\n",
        "original_word = \"lion\"\n",
        "synset_to_use = wn.synsets(original_word,'n')[0]\n",
        "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
        "\n",
        "print (\"original word: \",original_word.capitalize())\n",
        "print (distractors_calculated)\n",
        "\n",
        "\n",
        "original_word = \"bat\"\n",
        "synset_to_use = wn.synsets(original_word,'n')[0]\n",
        "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
        "\n",
        "print (\"\\noriginal word: \",original_word.capitalize())\n",
        "print (distractors_calculated)\n",
        "\n",
        "original_word = \"green\"\n",
        "synset_to_use = wn.synsets(original_word,'n')[0]\n",
        "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
        "\n",
        "print (\"\\noriginal word: \",original_word.capitalize())\n",
        "print (distractors_calculated)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original word:  Lion\n",
            "['Cheetah', 'Jaguar', 'Leopard', 'Liger', 'Saber-toothed Tiger', 'Snow Leopard', 'Tiger', 'Tiglon']\n",
            "\n",
            "original word:  Bat\n",
            "['Aardvark', 'Aquatic Mammal', 'Buck', 'Bull', 'Carnivore', 'Cow', 'Digitigrade Mammal', 'Doe', 'Edentate', 'Fissipedia', 'Flying Lemur', 'Hyrax', 'Insectivore', 'Lagomorph', 'Livestock', 'Pachyderm', 'Pangolin', 'Plantigrade Mammal', 'Primate', 'Proboscidean', 'Rodent', 'Tree Shrew', 'Unguiculata', 'Unguiculate', 'Ungulata', 'Ungulate', 'Yearling']\n",
            "\n",
            "original word:  Green\n",
            "['Blond', 'Blue', 'Brown', 'Complementary Color', 'Olive', 'Orange', 'Pastel', 'Pink', 'Purple', 'Red', 'Salmon', 'Yellow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjAk9r461aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59625e6b-4c8f-4e3b-db52-3e4ad1ff8601"
      },
      "source": [
        "#  An example of a word with two different senses\n",
        "original_word = \"cricket\"\n",
        "\n",
        "syns = wn.synsets(original_word,'n')\n",
        "\n",
        "for syn in syns:\n",
        "  print (syn, \": \",syn.definition(),\"\\n\" )\n",
        "\n",
        "\n",
        "synset_to_use = wn.synsets(original_word,'n')[0]\n",
        "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
        "\n",
        "print (\"\\noriginal word: \",original_word.capitalize())\n",
        "print (distractors_calculated)\n",
        "\n",
        "\n",
        "original_word = \"cricket\"\n",
        "synset_to_use = wn.synsets(original_word,'n')[1]\n",
        "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
        "\n",
        "print (\"\\noriginal word: \",original_word.capitalize())\n",
        "print (distractors_calculated)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('cricket.n.01') :  leaping insect; male makes chirping noises by rubbing the forewings together \n",
            "\n",
            "Synset('cricket.n.02') :  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs \n",
            "\n",
            "\n",
            "original word:  Cricket\n",
            "['Grasshopper']\n",
            "\n",
            "original word:  Cricket\n",
            "['Ball Game', 'Field Hockey', 'Football', 'Hurling', 'Lacrosse', 'Polo', 'Pushball', 'Ultimate Frisbee']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fHkvflE23f7"
      },
      "source": [
        "## 2. Using Conceptnet to generate distractors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4v8Ogp5GajK"
      },
      "source": [
        "https://conceptnet.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AyqbDyAJRAy"
      },
      "source": [
        "Question: Arnold Schwarzenegger served as a governor to which state?\n",
        "\n",
        "a) _________\n",
        "\n",
        "b) California\n",
        "\n",
        "c) _________\n",
        "\n",
        "d) _________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeB1VIcYI8s-"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import pprint"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEU2RN4aMLJx"
      },
      "source": [
        "Conceptnet API Documentation\n",
        "\n",
        "https://github.com/commonsense/conceptnet5/wiki/API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aJG8gxK4ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee33a7b2-5eb4-447e-b8d9-ed649ca41b37"
      },
      "source": [
        "word = \"California\"\n",
        "word = word.lower()\n",
        "if (len(word.split())>0):\n",
        "  word = word.replace(\" \",\"_\")\n",
        "\n",
        "\n",
        "url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "obj = requests.get(url).json()\n",
        "\n",
        "pprint.pprint (obj)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'@context': ['http://api.conceptnet.io/ld/conceptnet5.7/context.ld.json'],\n",
            " '@id': '/query?node=/c/en/california/n&rel=/r/PartOf&start=/c/en/california',\n",
            " 'edges': [{'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/southwest/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/southwest/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'Southwest',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/southwest'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[Southwest]]',\n",
            "            'weight': 2.0},\n",
            "           {'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/united_states/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/united_states/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'United States',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/united_states'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[United States]]',\n",
            "            'weight': 2.0}],\n",
            " 'version': '5.8.1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml3G8xmYNnyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabc7aa1-8de8-460b-cac9-30295e15c034"
      },
      "source": [
        "for edge in obj['edges']:\n",
        "  link = edge['end']['term']\n",
        "  print (link)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/c/en/southwest\n",
            "/c/en/united_states\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BS5B-Knbl8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f79cb2-0871-4008-bcea-5a7bf4923c2d"
      },
      "source": [
        "word = \"California\"\n",
        "word = word.lower()\n",
        "if (len(word.split())>0):\n",
        "  word = word.replace(\" \",\"_\")\n",
        "\n",
        "\n",
        "# url = \"http://api.conceptnet.io/query?node=/c/en/%s/n\"%(word)\n",
        "# url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf\"%(word)\n",
        "url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s\"%(word,word)\n",
        "obj = requests.get(url).json()\n",
        "\n",
        "pprint.pprint (obj)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'@context': ['http://api.conceptnet.io/ld/conceptnet5.7/context.ld.json'],\n",
            " '@id': '/query?node=/c/en/california/n&rel=/r/PartOf&start=/c/en/california',\n",
            " 'edges': [{'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/southwest/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/southwest/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'Southwest',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/southwest'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[Southwest]]',\n",
            "            'weight': 2.0},\n",
            "           {'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/united_states/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/united_states/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'United States',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/united_states'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[United States]]',\n",
            "            'weight': 2.0}],\n",
            " 'version': '5.8.1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqwL6fPQeSG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c8a995-ab5d-4ff9-fd0b-c8b71e148863"
      },
      "source": [
        "for edge in obj['edges']:\n",
        "  link = edge['end']['term']\n",
        "  print (link)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/c/en/southwest\n",
            "/c/en/united_states\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvZraDdkjMLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5dd8815-72b2-4ec3-f913-5c5b9ccc1dc8"
      },
      "source": [
        "\n",
        "for edge in obj['edges']:\n",
        "  link = edge['end']['term']\n",
        "  print (link)\n",
        "  distractor_list = []\n",
        "  url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "  obj2 = requests.get(url2).json()\n",
        "  for edge in obj2['edges']:\n",
        "      word2 = edge['start']['label']\n",
        "      if word2 not in distractor_list and word.lower() not in word2.lower():\n",
        "          distractor_list.append(word2)\n",
        "  print (distractor_list)\n",
        "  print (\"\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/c/en/southwest\n",
            "['Texas', 'Arizona', 'New Mexico', 'Nevada']\n",
            "\n",
            "\n",
            "/c/en/united_states\n",
            "['Kansas', 'New England', 'Florida', 'Montana', 'Twin', 'Alabama', 'Yosemite', 'Connecticut', 'Mid-Atlantic states', 'New Mexico']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roiBNFJFkEaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82232a6-d071-408d-deca-3b542e754f2c"
      },
      "source": [
        "# putting everything together\n",
        "# Distractors from http://conceptnet.io/\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = []\n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term']\n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "\n",
        "    return distractor_list\n",
        "\n",
        "original_word = \"California\"\n",
        "distractors = get_distractors_conceptnet(original_word)\n",
        "\n",
        "print (\"Original word: \",original_word)\n",
        "print (\"\\nDistractors \",distractors)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original word:  California\n",
            "\n",
            "Distractors  ['Texas', 'Arizona', 'New Mexico', 'Nevada', 'Kansas', 'New England', 'Florida', 'Montana', 'Twin', 'Alabama', 'Yosemite', 'Connecticut', 'Mid-Atlantic states']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcnbEBNKBVQP"
      },
      "source": [
        "## 3. Using Wordvectors (sense2vec) to generate distractors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HmzOkegsF6x6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLqP0t7YBehq"
      },
      "source": [
        "https://github.com/explosion/sense2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mtgzRVTZO4t"
      },
      "source": [
        "Download sense2vec wordvectors and unzip them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pFeI21keY_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7988559b-0588-4720-d997-862c0670c4a0"
      },
      "source": [
        "# !pip install sense2vec==1.0.2\n",
        "!pip install sense2vec==2.0.1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sense2vec==2.0.1\n",
            "  Downloading sense2vec-2.0.1-py2.py3-none-any.whl.metadata (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from sense2vec==2.0.1) (3.8.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from sense2vec==2.0.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from sense2vec==2.0.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from sense2vec==2.0.1) (2.0.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from sense2vec==2.0.1) (2.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (8.3.6)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.1) (0.1.2)\n",
            "Downloading sense2vec-2.0.1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sense2vec\n",
            "Successfully installed sense2vec-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWL0HdMEZXl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a6d67c-3b93-4e33-abc6-6b8aabb0f3b5"
      },
      "source": [
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-22 15:22:27--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250422T152227Z&X-Amz-Expires=300&X-Amz-Signature=47964ed4075fe9786e2b1110b28a3b13ecbfa89b5b4a44c220b6cdf7751b03e6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-22 15:22:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250422T152227Z&X-Amz-Expires=300&X-Amz-Signature=47964ed4075fe9786e2b1110b28a3b13ecbfa89b5b4a44c220b6cdf7751b03e6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M  34.6MB/s    in 19s     \n",
            "\n",
            "2025-04-22 15:22:47 (30.1 MB/s) - ‘s2v_reddit_2015_md.tar.gz’ saved [600444501/600444501]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ZcqDV8Zcse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3671e066-c13b-44ce-ed5e-6bf18b9a617d"
      },
      "source": [
        "!tar -xvf  s2v_reddit_2015_md.tar.gz"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCgIZGlZgSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f27a9b1-1cd1-4e7e-fece-7f50e349c37d"
      },
      "source": [
        "!ls s2v_old"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cfg  freqs.json  key2row  strings.json\tvectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9gTgCnfaHTv"
      },
      "source": [
        "# load sense2vec vectors\n",
        "from sense2vec import Sense2Vec\n",
        "s2v = Sense2Vec().from_disk('s2v_old')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PqzoxLfg-PD"
      },
      "source": [
        "Who is the 45th president of the United States?\n",
        "\n",
        "a) ___________\n",
        "\n",
        "b) ___________\n",
        "\n",
        "c) Donald Trump\n",
        "\n",
        "d) ___________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzAt0CP_gssV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2a2f88-6e76-44a8-9284-6eb3bba6197f"
      },
      "source": [
        "word = \"Donald Trump\"\n",
        "word = word.lower()\n",
        "word = word.replace(\" \", \"_\")\n",
        "\n",
        "print (\"word \",word)\n",
        "\n",
        "sense = s2v.get_best_sense(word)\n",
        "\n",
        "print (\"Best sense \",sense)\n",
        "most_similar = s2v.most_similar(sense, n=12)\n",
        "\n",
        "\n",
        "print (most_similar)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word  donald_trump\n",
            "Best sense  Donald_Trump|PERSON\n",
            "[('Sarah_Palin|PERSON', np.float32(0.8547)), ('Mitt_Romney|PERSON', np.float32(0.8246)), ('Barrack_Obama|PERSON', np.float32(0.8082)), ('Bill_Clinton|PERSON', np.float32(0.8046)), ('Oprah|GPE', np.float32(0.8042)), ('Paris_Hilton|ORG', np.float32(0.7963)), ('Palin|GPE', np.float32(0.7953)), ('Oprah_Winfrey|PERSON', np.float32(0.7941)), ('Stephen_Colbert|PERSON', np.float32(0.7927)), ('Oprah|PERSON', np.float32(0.79)), ('Hilary_Clinton|PERSON', np.float32(0.7896)), ('Herman_Cain|PERSON', np.float32(0.787))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJRI3S8FiXzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469b06d6-1d8d-4576-8619-6f96e2c48a48"
      },
      "source": [
        "distractors = []\n",
        "\n",
        "for each_word in most_similar:\n",
        "  append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \").lower()\n",
        "  if append_word.lower() != word:\n",
        "      distractors.append(append_word.title())\n",
        "\n",
        "print (distractors)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sarah Palin', 'Mitt Romney', 'Barrack Obama', 'Bill Clinton', 'Oprah', 'Paris Hilton', 'Palin', 'Oprah Winfrey', 'Stephen Colbert', 'Oprah', 'Hilary Clinton', 'Herman Cain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy0ZSo3bi5Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9331b908-d21a-44dd-8edd-d76961d1caa9"
      },
      "source": [
        "from collections import OrderedDict\n",
        "def sense2vec_get_words(word,s2v):\n",
        "    output = []\n",
        "    word = word.lower()\n",
        "    word = word.replace(\" \", \"_\")\n",
        "\n",
        "    sense = s2v.get_best_sense(word)\n",
        "    most_similar = s2v.most_similar(sense, n=20)\n",
        "\n",
        "    # print (\"most_similar \",most_similar)\n",
        "\n",
        "    for each_word in most_similar:\n",
        "        append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \").lower()\n",
        "        if append_word.lower() != word:\n",
        "            output.append(append_word.title())\n",
        "\n",
        "    out = list(OrderedDict.fromkeys(output))\n",
        "    return out\n",
        "\n",
        "word = \"Natural Language processing\"\n",
        "distractors = sense2vec_get_words(word,s2v)\n",
        "\n",
        "print (\"Distractors for \",word, \" : \")\n",
        "print (distractors)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distractors for  Natural Language processing  : \n",
            "['Machine Learning', 'Computer Vision', 'Deep Learning', 'Data Analysis', 'Neural Nets', 'Relational Databases', 'Algorithms', 'Neural Networks', 'Data Processing', 'Image Recognition', 'Nlp', 'Big Data', 'Data Science', 'Big Data Analysis', 'Information Retrieval', 'Speech Recognition', 'Programming Languages']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w7j5_2Lj0e_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fff75a-dca1-4228-d02a-584ac1284fbc"
      },
      "source": [
        "word = \"USA\"\n",
        "distractors = sense2vec_get_words(word,s2v)\n",
        "\n",
        "print (\"Distractors for \",word, \" : \")\n",
        "print (distractors)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distractors for  USA  : \n",
            "['Usa.', 'U.S', 'U.S.', 'Us.', 'Us', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9wmEDvr7sFB"
      },
      "source": [
        "## Assignment Solution - Filter distractors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJZYuBM-7z4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a352c1d-6c5b-43bc-bfcf-1645f5820d37"
      },
      "source": [
        "!pip install strsim==0.0.3"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: strsim==0.0.3 in /usr/local/lib/python3.11/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j_iVh098xhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b6be02-dbfe-44dd-839e-c162bcea755d"
      },
      "source": [
        "import string\n",
        "# A function to get all the edits for a word\n",
        "def edits(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz '+string.punctuation\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "print (edits(\"cat\"))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'caqt', 'ca\\\\t', 'vcat', 'capt', 'ca~t', 'c&at', 'cat(', 'ca\\\\', 'ca<t', 'wcat', 'cait', 'ca t', 'cat%', 'c(at', 'ca ', 'cat,', 'caf', 'cat\\\\', '`cat', 'ca!t', 'ca*t', 'catc', \"c't\", 'cat~', 'ecat', '/at', 'cau', ':cat', 'ctat', '<cat', ';cat', 'can', 'cast', 'cabt', 'cat/', '~at', 'cat ', 'catv', 'c\"t', 'clt', 'caz', 'caxt', 'c)t', 'cwat', 'c\"at', 'chat', 'crat', 'ca&', 'cawt', '=cat', 'ciat', 'c,t', 'cat>', 'catk', 'caet', 'ca_', 'ctt', 'c_t', '\\\\at', 'hat', '.at', 'cat:', \"'cat\", 'c;at', 'ca<', 'bcat', 'ca%', 'ca.t', 'ca-t', 'ca\"', 'ca]t', 'gcat', 'c=at', 'cat#', '_at', '_cat', 'oat', \"ca't\", 'c}t', 'cwt', 'cbat', 'ca`', 'act', 'ca?', 'rat', '}at', 'pat', 'ca:', 'cat[', '*cat', 'cat<', 'cqt', 'cgt', 'crt', 'ucat', 'ca;', 'ncat', 'c[t', 'cad', ')cat', 'c!at', 'vat', 'cat*', 'c=t', 'acat', 'cmat', 'cat@', \"ca'\", 'ceat', 'cadt', ']at', 'cab', 'rcat', 'cdt', 'lcat', 'ca+', 'catb', 'cayt', 'c>at', 'cas', 'ca~', 'ca#', 'cjat', 'ca?t', 'mat', 'c@at', '\\\\cat', 'cot', '@cat', ')at', 'c|t', 'caat', 'ca%t', 'lat', 'ckt', 'cat`', 'cao', 'yat', 'zat', '>cat', 'c~t', 'cvt', 'sat', '\"at', 'caot', ':at', 'ca@', 'ca)', 'ocat', 'cet', 'cat&', 'ca(t', 'eat', 'iat', 'cat.', '|cat', '{at', 'catt', 'czat', \"'at\", 'catg', 'ca:t', 'ca(', 'dcat', 'cav', '#at', 'cpt', 'c*at', 'cht', 'c_at', 'ca{t', 'cat_', 'catw', ']cat', ',at', 'cat-', 'icat', 'dat', 'c>t', 'ca^t', '%cat', 'c.at', 'c(t', 'c%t', '^at', 'ca-', 'xat', 'c^t', 'cats', 'cat|', 'cat', 'cut', 'catj', 'c*t', 'c@t', 'pcat', 'cbt', 'xcat', 'cate', 'cit', '@at', 'cct', '$at', 'cat;', 'cxt', '[cat', 'ca\"t', 'c+at', 'c/t', '$cat', '=at', 'ca.', 'ca', '!at', 'ccat', 'c\\\\at', 'cal', 'c&t', 'catf', 'c,at', 'c`at', 'c^at', 'hcat', 'ca_t', 'jcat', '}cat', 'ckat', 'czt', 'ca&t', 'c)at', '^cat', 'cnt', 'cpat', 'cay', '(cat', 'cae', '?cat', 'cnat', 'ca`t', 'caq', 'ca,t', 'c$at', 'cam', 'c<at', 'cjt', 'ca,', 'cap', 'c{t', 'ca|t', 'c~at', '*at', 'c;t', 'coat', 'catx', 'cato', 'ca/', 'c]at', '~cat', 'c|at', 'cat=', '&at', \"c'at\", 'ca{', 'c{at', 'gat', 'c:t', 'cat}', 'caa', 'ca=', 'ca[', 'mcat', 'ca;t', 'cat)', 'c.t', 'fcat', 'c/at', 'c:at', 'ca>t', 'cata', 'kcat', '<at', 'caw', 'ca)t', 'cag', 'caty', 'aat', 'cat?', 'ca*', 'ct', 'c#at', 'kat', 'scat', 'cai', 'cac', 'cati', 'cat]', 'ca]', 'ca}t', '.cat', 'cat!', '+cat', 'c\\\\t', 'catp', ' cat', ',cat', 'ca>', 'ca=t', 'cyt', 'ca#t', 'cat^', '/cat', '-cat', 'cath', 'c-at', 'c]t', '#cat', 'cxat', 'cfat', 'wat', '>at', 'zcat', 'catq', 'uat', 'cyat', '&cat', 'c?at', 'ca}', 'catd', 'ca$t', 'car', '[at', 'catl', 'catn', 'c%at', 'csat', ' at', '%at', 'cuat', 'caut', 'tcat', 'c<t', \"cat'\", 'c[at', 'calt', 'c#t', 'cavt', '|at', 'caft', 'cta', 'cvat', '{cat', 'cart', '(at', '-at', 'cft', 'ca/t', 'cat\"', 'qcat', 'c`t', 'at', 'c!t', 'cakt', 'catm', 'cak', 'c$t', 'c+t', 'cah', 'catu', 'cqat', 'ca^', '+at', 'cajt', 'catz', 'ca!', 'jat', 'cat{', 'c}at', 'cdat', 'cact', 'ca$', 'caj', 'c?t', 'cmt', 'fat', 'caht', 'ca+t', ';at', 'c t', 'ca@t', 'cax', 'ca[t', 'ca|', 'cst', 'cat+', 'cat$', '\"cat', 'cazt', '`at', 'cagt', 'camt', 'c at', 'cant', 'c-t', '?at', 'cgat', 'clat', 'ycat', '!cat', 'bat', 'nat', 'catr', 'tat', 'qat'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVZSttVHIM1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb7f1ff-ab9a-474a-97f3-5696b6ab5225"
      },
      "source": [
        "word = \"USA\"\n",
        "distractors = sense2vec_get_words(word,s2v)\n",
        "\n",
        "print (\"Distractors for \",word, \" : \")\n",
        "print (distractors)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distractors for  USA  : \n",
            "['Usa.', 'U.S', 'U.S.', 'Us.', 'Us', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8wQhYsRI7wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d25647-863a-4af0-8a81-a1514dc55db5"
      },
      "source": [
        "all_edits = edits (word.lower())\n",
        "print (all_edits)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'usag', 'upsa', 'uoa', 'uesa', 'us<a', 'u\"a', 'uasa', 'usw', '^sa', 'usza', 'usa.', 'us+a', 'u/a', 'uqa', 'uwsa', 'uvsa', 'uba', 'wsa', 'us*a', 'us]a', 'uwa', 'umsa', 'u;a', 'utsa', 'usk', 'ousa', 'u#a', 'u)a', 'us.a', 'usi', '}usa', '<sa', 'vusa', 'us`a', 'fusa', 'us[', 'us(a', 'us/', 'usak', '\\\\usa', 'u*a', 'usv', 'us`', 'u,sa', '*sa', 'u(a', 'ubsa', 'fsa', 'usar', '+sa', 'xsa', 'u sa', 'usua', 'usfa', 'us>a', 'us=a', 'u@sa', 'qsa', 'us\"a', 'uzsa', 'usxa', 'usa-', '@sa', 'usa|', 'us,a', 'asa', 'osa', 'u,a', 'usia', 'rsa', 'usma', 'eusa', 'us(', 'us{a', 'u#sa', 'u)sa', 'us\\\\a', 'usa{', 'u]a', 'uya', 'usba', '$usa', 'u\\\\sa', 'us)', 'usj', '*usa', 'susa', 'ura', \"'sa\", 'u-sa', 'u(sa', 'u*sa', 'usp', 'usm', 'us-a', '#sa', 'busa', 'uma', '`usa', 'usax', 'ursa', 'usa~', 'u<a', 'jusa', 'us!', 'us@a', 'usla', 'us.', 'usea', 'usva', 'us^a', 'psa', 'zsa', 'usa@', \"us'\", 'uspa', 'uksa', 'us:a', 'usao', 'usa:', 'u|a', '-sa', 'usas', 'usat', 'u%a', 'una', 'usta', 'uva', 'uta', 'u~sa', 'u^sa', 'pusa', 'u$sa', ';usa', ':sa', 'usam', 'usa;', ')usa', 'usaq', '.usa', 'lsa', ' usa', 'us^', 'tusa', 'uia', ';sa', 'qusa', 'usa,', 'us]', 'ust', 'uja', 'u a', 'us_', 'uka', \"u'sa\", 'u.sa', 'u}sa', 'us=', 'uxsa', 'husa', 'ysa', 'uua', \"u'a\", 'us;', 'us!a', 'u:a', 'usa}', 'hsa', 'xusa', 'usha', 'ugsa', 'usl', 'uhsa', '=sa', '-usa', 'usb', '\"usa', 'usga', 'usa[', 'usa=', 'usah', 'u\"sa', 'usya', 'usad', 'usaw', 'yusa', 'us?a', 'usa(', 'uea', '|sa', 'u`sa', '!sa', 'u:sa', '^usa', '>usa', 'uga', '[sa', 'us?', 'usa\"', 'u]sa', 'usoa', 'us#a', 'us/a', 'u/sa', 'usa/', 'us\\\\', 'gusa', '~usa', 'u>a', 'ujsa', ']usa', '?usa', 'dusa', '(sa', 'uas', 'us a', '`sa', 'kusa', 'uswa', 'usa>', 'u_sa', '&sa', 'usap', 'usa+', 'usa', 'bsa', 'uxa', 'usau', 'msa', 'u?a', 'uisa', 'uysa', 'u_a', 'uss', 'iusa', 'us', 'usca', 'csa', 'us>', 'us|', 'usai', '(usa', 'usaa', 'usf', 'u=sa', 'us+', 'upa', 'usa%', 'uosa', 'u;sa', 'usa<', 'us_a', 'u|sa', 'usda', 'us$', 'usa*', 'us@', \"usa'\", 'us&', 'u}a', 'udsa', '\\\\sa', 'u=a', 'usa$', 'usa#', '_sa', 'u$a', 'us|a', 'ucsa', 'u>sa', 'uza', 'u?sa', 'usa\\\\', 'u@a', 'ua', 'usra', 'usy', 'ksa', 'u`a', 'u{sa', '\"sa', 'us~', 'u!a', '=usa', 'us%a', 'usg', 'u+a', 'usa_', 'sa', 'ausa', 'usal', 'jsa', 'usaf', 'ula', 'usz', 'usa^', '%usa', 'isa', '%sa', 'us:', '/sa', 'usn', 'usr', 'ulsa', 'wusa', 'u-a', ':usa', 'us)a', 'uusa', 'usa`', \"'usa\", ' sa', 'usx', 'ussa', 'us;a', '_usa', 'usqa', 'us$a', ',usa', 'ush', 'use', 'us*', 'us-', 'usa]', 'u~a', '}sa', 'usay', 'us&a', 'us#', 'u[a', 'unsa', 'us}a', 'usa?', '>sa', 'vsa', 'ufa', 'nusa', 'usu', 'usaj', 'us ', 'cusa', '/usa', 'usav', 'u.a', 'ufsa', 'us{', 'uca', 'us<', '?sa', 'us}', ',sa', 'u\\\\a', 'uso', 'usac', 'u^a', ')sa', 'gsa', 'usja', 'us~a', 'uqsa', 'usan', 'usa!', 'zusa', 'esa', 'u&sa', \"us'a\", 'uska', 'lusa', 'usae', 'dsa', '&usa', 'us\"', 'u%sa', 'us[a', 'musa', 'uaa', '{usa', '.sa', 'uda', '~sa', 'us,', 'u+sa', 'us%', 'u!sa', 'usc', 'usab', ']sa', 'usa ', '@usa', 'usna', 'usaz', 'ssa', '<usa', 'u&a', '#usa', '[usa', '|usa', 'u<sa', '+usa', 'nsa', 'sua', 'u{a', '!usa', 'rusa', 'usq', 'uha', '$sa', 'usd', '{sa', 'usa&', 'u[sa', 'tsa', 'usa)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBCPtA3HJIGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f3215c-827b-44db-dfae-a8865dd26f81"
      },
      "source": [
        "filtered_distractors_edit_distance = [x for x in distractors if x.lower() not in all_edits]\n",
        "print (filtered_distractors_edit_distance)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['U.S', 'U.S.', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOfDpeOlTgHs"
      },
      "source": [
        "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
        "normalized_levenshtein = NormalizedLevenshtein()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaSo04a4TjfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9036a4c5-84a0-49bb-f199-287f3bd07908"
      },
      "source": [
        "\n",
        "print (\"Levenshtein Distance USA  & U.S.A  ->\", normalized_levenshtein.distance(\"USA\",\"U.S.A\"))\n",
        "print (\"Levenshtein Distance USA  & U.S  ->\", normalized_levenshtein.distance(\"USA\",\"U.S\"))\n",
        "print (\"Levenshtein Distance USA  & America  ->\", normalized_levenshtein.distance(\"USA\",\"America\"))\n",
        "print (\"Levenshtein Distance USA  & Canada  ->\", normalized_levenshtein.distance(\"USA\",\"Canada\"))\n",
        "print (\"Levenshtein Distance USA  & United States  ->\", normalized_levenshtein.distance(\"USA\",\"United States\"))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Levenshtein Distance USA  & U.S.A  -> 0.4\n",
            "Levenshtein Distance USA  & U.S  -> 0.6666666666666666\n",
            "Levenshtein Distance USA  & America  -> 1.0\n",
            "Levenshtein Distance USA  & Canada  -> 1.0\n",
            "Levenshtein Distance USA  & United States  -> 0.8461538461538461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFbwVj1ObLcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63cf766-6cb3-42bc-dc1e-781897e7b108"
      },
      "source": [
        "threshold = 0.7\n",
        "filtered_distractors_edit_distance_and_levenshtein_distance =[[x for x in filtered_distractors_edit_distance if normalized_levenshtein.distance(x.lower(),word.lower())>threshold] ]\n",
        "print (filtered_distractors_edit_distance_and_levenshtein_distance)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['America', 'Canada', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYQVvewgbq1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae7eb8d-136d-4bff-aebb-b4aa2956fdcd"
      },
      "source": [
        "print (distractors)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Usa.', 'U.S', 'U.S.', 'Us.', 'Us', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2z5HC6SH4at"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}